# EvalEval

Perturbation Checklist for Evaluating NLG Evaluation Metrics

## Contents

- [Overview](#Overview)
- [Setup](#Setup)
- [Templates](#Templates)
  - [Data-to-Text Generation](#Data-to-Text Generation)
  - [Image Captioning](###Image Captioning)
  - [Translation]()
  - [Dialogue]()
  - [Summarization]()
  - [Question Generation]()
- [Human Evaluations]()
- [Metircs]()
- [Citation]()

## Overview

## Setup
`
python3 main.py --task IC --linguistic_criteria Invariance --ref_file data/model_annotations.aligned.jsonl --output_file example
`
## Templates

### Data-to-Text Generation

### Image Captioning

### Translation

### Dialogue

### Summarization

### Question Generation

## Human Evaluations

## Metircs

Coming soon ..

## Citation

If you find our work usefull please cite
`

`
